{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH=\"../Datasets/Dataset\"\n",
    "PREPROCESSED_PATH=\"../Preprocessed_Datasets/Dataset\"\n",
    "AUGMENTED_PATH=\"../Augmented_Datasets/Dataset\"\n",
    "AUGMENTED_PATH_TRAIN_EX=\"../Augmented_Datasets/Dataset_train\" # Data exclusively for training, not validating\n",
    "YOLO_PATH=\"../YOLO_Datasets/Dataset\"\n",
    "YOLO_PATH_TRAIN_EX=\"../YOLO_Datasets/Dataset_train\" # Data exclusively for training, not validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(AUGMENTED_PATH):\n",
    "    os.makedirs(AUGMENTED_PATH)\n",
    "if not os.path.exists(AUGMENTED_PATH_TRAIN_EX):\n",
    "    os.makedirs(AUGMENTED_PATH_TRAIN_EX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we will apply the following augmentation techniques:\n",
    "- Hue transformations (-100º to +100º)\n",
    "- Contrast inversion (To simulate dark and light modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_slices(DATASET_PATH, AUGMENTED_PATH, 3, 3, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply resize now and not before because we want all images, including tiles, to keep the image size that the model will take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_dataset_images(DATASET_PATH, AUGMENTED_PATH, 640, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_augmentation(AUGMENTED_PATH, AUGMENTED_PATH_TRAIN_EX, 0.15, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_inversion_augmentation(AUGMENTED_PATH, AUGMENTED_PATH_TRAIN_EX, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the augmented data to the train exclusively folder\n",
    "for file in os.listdir(AUGMENTED_PATH):\n",
    "    shutil.copy(os.path.join(AUGMENTED_PATH, file), AUGMENTED_PATH_TRAIN_EX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORMAT CONVERSION\n",
    "\n",
    "Up to now, we have treated with labelme format datasets, but we need to convert it to YOLOv8 format if we want to train\n",
    "a model, which has the following format:\n",
    "\n",
    "```\n",
    "YOLOv8_Dataset/\n",
    "├── data.yaml\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   │   ├── img1.jpg\n",
    "│   │   ├── img2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── labels/\n",
    "│   │   ├── img1.txt\n",
    "│   │   ├── img2.txt\n",
    "│   │   └── ...\n",
    "├── valid/\n",
    "│   ├── images/\n",
    "│   │   ├── img1.jpg\n",
    "│   │   ├── img2.jpg\n",
    "│   │   └── ...\n",
    "│   ├── labels/\n",
    "│   │   ├── img1.txt\n",
    "│   │   ├── img2.txt\n",
    "│   │   └── ...\n",
    "└── test/ (OPTIONAL)\n",
    "    ├── images/\n",
    "    │   ├── img1.jpg\n",
    "    │   ├── img2.jpg\n",
    "    │   └── ...\n",
    "    └── labels/\n",
    "        ├── img1.txt\n",
    "        ├── img2.txt\n",
    "        └── ...\n",
    "```\n",
    "\n",
    "The format of the data.yml file is:\n",
    "```\n",
    "path: <path_to_dataset_root_dit>\n",
    "train: <path_to_train_images>\n",
    "val: <path_to_validation_images>\n",
    "test: <path_to_test_images> (OPTIONAL)\n",
    "\n",
    "nc: <number_of_classes>\n",
    "names: ['class1', 'class2', 'class3', ...]\n",
    "```\n",
    "\n",
    "The labels for Instance segmentation have the following format for each annotation:\n",
    "```\n",
    "<class-index> <x1> <y1> <x2> <y2> ... <xn> <yn>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelme_to_yolo(AUGMENTED_PATH_TRAIN_EX, YOLO_PATH_TRAIN_EX, 0.7,[\n",
    "                    \"WebIcon\",\n",
    "                    \"Icon\",\n",
    "                    \"Switch\",\n",
    "                    \"BtnSq\",\n",
    "                    \"BtnPill\",\n",
    "                    \"BtnCirc\",\n",
    "                    \"CheckboxChecked\",\n",
    "                    \"CheckboxUnchecked\",\n",
    "                    \"RadiobtnSelected\",\n",
    "                    \"RadiobtnUnselected\",\n",
    "                    \"TextInput\",\n",
    "                    \"Dropdown\",\n",
    "                    \"Link\",\n",
    "                    \"Text\",\n",
    "                    \"TabActive\",\n",
    "                    \"TabInactive\",\n",
    "                    \"Sidebar\",\n",
    "                    \"Navbar\",\n",
    "                    \"Container\",\n",
    "                    \"Image\",\n",
    "                    \"BrowserURLInput\",\n",
    "                    \"Header\",\n",
    "                    \"Toolbar\",\n",
    "                    \"BrowserToolbar\",\n",
    "                    \"Scrollbar\",\n",
    "                    \"Application\",\n",
    "                    \"Taskbar\",\n",
    "                    \"Dock\",\n",
    "                ], \"seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform fine-tuning over the mobile-sam model using the hyperparameter tuning provided by Ultralytics to get the\n",
    "best results we can. Since this is a non-standard dataset in terms of object features it is not clear what are the values\n",
    "we should use.\n",
    "\n",
    "We will also configure the training to not do any augmentation over the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt to 'yolov8s-seg.pt'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72339da425b34485848e6078805b0e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/22.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"yolov8s-seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.209 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208  Python-3.9.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "WARNING  Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=../YOLO_Datasets/Dataset_train/data.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=1, project=None, name=train90, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train90\n",
      "Overriding model.yaml nc=80 with nc=28\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2781380  ultralytics.nn.modules.head.Segment          [28, 32, 128, [128, 256, 512]]\n",
      "YOLOv8s-seg summary: 261 layers, 11800932 parameters, 11800916 gradients, 42.7 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\labels.cache... 92 images, 0 backgrounds, 9 corrupt: 100%|██████████| 92/92 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (43)_1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (43)_1_contrast_inversion_augmented.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (70)_1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (70)_2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (71)_1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (84)_1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (84)_2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001      1.0001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (84)_2_hue_augmented.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001      1.0001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\train\\images\\Captura de pantalla (85)_2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0001]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Code\\Screen2SOM-Training\\YOLO_Datasets\\Dataset_train\\val\\labels.cache... 45 images, 0 backgrounds, 0 corrupt: 100%|██████████| 45/45 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train90\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/30      10.4G      2.931       6.34      5.299      1.749        437        640: 100%|██████████| 6/6 [04:08<00:00, 41.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:20<00:00, 10.31s/it]\n",
      "                   all         45       6729      0.344     0.0443     0.0391     0.0182    0.00381     0.0093    0.00237   0.000695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/30      8.98G      2.346      4.888      3.576       1.43        688        640: 100%|██████████| 6/6 [02:39<00:00, 26.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|█████     | 1/2 [00:14<00:14, 14.17s/it]WARNING  NMS time limit 1.150s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:25<00:00, 12.90s/it]\n",
      "                   all         45       6729      0.014    0.00794     0.0075     0.0026   0.000455   0.000247   0.000231   8.34e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/30      9.92G      2.212      3.977      2.558      1.387        489        640: 100%|██████████| 6/6 [02:34<00:00, 25.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|█████     | 1/2 [00:17<00:17, 17.34s/it]WARNING  NMS time limit 1.150s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:27<00:00, 13.74s/it]\n",
      "                   all         45       6729   0.000552   0.000912   0.000307   6.15e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/30      9.49G      2.078      3.738       2.24      1.346       4050        640:  33%|███▎      | 2/6 [01:13<02:27, 36.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Screen2SOM-Training\\Training\\everything.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Screen2SOM-Training/Training/everything.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Tune hyperparameters on dataset for 30 epochs\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Screen2SOM-Training/Training/everything.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mYOLO_PATH_TRAIN_EX\u001b[39m}\u001b[39;49;00m\u001b[39m/data.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, optimizer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAdamW\u001b[39;49m\u001b[39m'\u001b[39;49m, plots\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, hsv_h\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, hsv_s\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, hsv_v\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, fliplr\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:338\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    339\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:190\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:337\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamp):\n\u001b[0;32m    336\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m RANK \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    339\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m world_size\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:41\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m    (torch.Tensor): The output of the network.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:212\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_criterion()\n\u001b[0;32m    211\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(batch[\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mif\u001b[39;00m preds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m preds\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion(preds, batch)\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\utils\\loss.py:272\u001b[0m, in \u001b[0;36mv8SegmentationLoss.__call__\u001b[1;34m(self, preds, batch)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtuple\u001b[39m(masks\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]) \u001b[39m!=\u001b[39m (mask_h, mask_w):  \u001b[39m# downsample\u001b[39;00m\n\u001b[0;32m    270\u001b[0m         masks \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(masks[\u001b[39mNone\u001b[39;00m], (mask_h, mask_w), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 272\u001b[0m     loss[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_segmentation_loss(fg_mask, masks, target_gt_idx, target_bboxes, batch_idx, proto,\n\u001b[0;32m    273\u001b[0m                                                pred_masks, imgsz, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverlap)\n\u001b[0;32m    275\u001b[0m \u001b[39m# WARNING: lines below prevent Multi-GPU DDP 'unused gradient' PyTorch errors, do not remove\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     loss[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (proto \u001b[39m*\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m+\u001b[39m (pred_masks \u001b[39m*\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()  \u001b[39m# inf sums may lead to nan loss\u001b[39;00m\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\utils\\loss.py:366\u001b[0m, in \u001b[0;36mv8SegmentationLoss.calculate_segmentation_loss\u001b[1;34m(self, fg_mask, masks, target_gt_idx, target_bboxes, batch_idx, proto, pred_masks, imgsz, overlap)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m         gt_mask \u001b[39m=\u001b[39m masks[batch_idx\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m i][mask_idx]\n\u001b[1;32m--> 366\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingle_mask_loss(gt_mask, pred_masks_i[fg_mask_i], proto_i, mxyxy_i[fg_mask_i],\n\u001b[0;32m    367\u001b[0m                                   marea_i[fg_mask_i])\n\u001b[0;32m    369\u001b[0m \u001b[39m# WARNING: lines below prevents Multi-GPU DDP 'unused gradient' PyTorch errors, do not remove\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (proto \u001b[39m*\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum() \u001b[39m+\u001b[39m (pred_masks \u001b[39m*\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msum()  \u001b[39m# inf sums may lead to nan loss\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters on dataset for 30 epochs\n",
    "model.train(data=f\"{YOLO_PATH_TRAIN_EX}/data.yaml\", workers=1, epochs=30, optimizer='AdamW', plots=False, save=True, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, fliplr=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/segment/tune2/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "WARNING  'SAM' model does not support 'val' mode for 'segment' task yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:418\u001b[0m, in \u001b[0;36mModel._smart_load\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 418\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask_map[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask][key]\n\u001b[0;32m    419\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'validator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Screen2SOM-Training\\Training\\elements.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Screen2SOM-Training/Training/elements.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Validate the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/Screen2SOM-Training/Training/elements.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mval(workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)  \u001b[39m# no arguments needed, dataset and settings remembered\u001b[39;00m\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:275\u001b[0m, in \u001b[0;36mModel.val\u001b[1;34m(self, validator, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m custom \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrect\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m}  \u001b[39m# method defaults\u001b[39;00m\n\u001b[0;32m    273\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverrides, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m'\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m}  \u001b[39m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m validator \u001b[39m=\u001b[39m (validator \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_smart_load(\u001b[39m'\u001b[39;49m\u001b[39mvalidator\u001b[39;49m\u001b[39m'\u001b[39;49m))(args\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m    276\u001b[0m validator(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[0;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[1;32md:\\Code\\Screen2SOM-Training\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py:422\u001b[0m, in \u001b[0;36mModel._smart_load\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    420\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    421\u001b[0m mode \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mstack()[\u001b[39m1\u001b[39m][\u001b[39m3\u001b[39m]  \u001b[39m# get the function name.\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    423\u001b[0m     emojis(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWARNING ⚠️ \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m model does not support \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m mode for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m task yet.\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: WARNING  'SAM' model does not support 'val' mode for 'segment' task yet."
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "metrics = model.val(workers=1)  # no arguments needed, dataset and settings remembered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.19274,     0.32869,     0.40419,     0.39927,       0.561,     0.28032,     0.10029,     0.16814,     0.26469,     0.19651,     0.35886,     0.31838,     0.15703])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.seg.map    # map50-95\n",
    "metrics.seg.map50  # map50\n",
    "metrics.seg.map75  # map75\n",
    "metrics.seg.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.44217,     0.57988,      0.5628,     0.66923,     0.72803,     0.39053,     0.33478,     0.53026,     0.41717,     0.49925,     0.55777,     0.43547,      0.2592])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Code\\Screen2SOM-Training\\Training\\..\\YOLO_Datasets\\Elementlevel_train\\val\\images\\Captura de pantalla (44)_2.jpg: 384x640 33 WebIcons, 4 Icons, 3 BtnPills, 3 TextInputs, 2 Links, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inference = model(\"../YOLO_Datasets/Elementlevel_train/val/images/Captura de pantalla (44)_2.jpg\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mobile-SAM\n",
    "from ultralytics import SAM\n",
    "\n",
    "model = SAM(\"mobile_sam.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs\\detect\\tune2'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/20 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/20 iterations complete  (1157.84s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.53156 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75375, 'metrics/recall(B)': 0.57982, 'metrics/mAP50(B)': 0.6638, 'metrics/mAP50-95(B)': 0.51687, 'val/box_loss': 0.87578, 'val/cls_loss': 0.80861, 'val/dfl_loss': 0.83703, 'fitness': 0.53156}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/20 with hyperparameters: {'lr0': 0.00995, 'lrf': 0.01067, 'momentum': 0.90942, 'weight_decay': 0.00051, 'warmup_epochs': 2.98539, 'warmup_momentum': 0.83792, 'box': 7.5, 'cls': 0.48537, 'dfl': 1.69666, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/20 iterations complete  (2295.66s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.54557 observed at iteration 2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.78185, 'metrics/recall(B)': 0.61188, 'metrics/mAP50(B)': 0.67917, 'metrics/mAP50-95(B)': 0.53072, 'val/box_loss': 0.89689, 'val/cls_loss': 0.79098, 'val/dfl_loss': 0.94551, 'fitness': 0.54557}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00995\n",
      "lrf: 0.01067\n",
      "momentum: 0.90942\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 2.98539\n",
      "warmup_momentum: 0.83792\n",
      "box: 7.5\n",
      "cls: 0.48537\n",
      "dfl: 1.69666\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/20 with hyperparameters: {'lr0': 0.01079, 'lrf': 0.00963, 'momentum': 0.88845, 'weight_decay': 0.00051, 'warmup_epochs': 2.76185, 'warmup_momentum': 0.92447, 'box': 7.81391, 'cls': 0.48281, 'dfl': 1.73287, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/20 iterations complete  (3432.74s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.54557 observed at iteration 2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.78185, 'metrics/recall(B)': 0.61188, 'metrics/mAP50(B)': 0.67917, 'metrics/mAP50-95(B)': 0.53072, 'val/box_loss': 0.89689, 'val/cls_loss': 0.79098, 'val/dfl_loss': 0.94551, 'fitness': 0.54557}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00995\n",
      "lrf: 0.01067\n",
      "momentum: 0.90942\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 2.98539\n",
      "warmup_momentum: 0.83792\n",
      "box: 7.5\n",
      "cls: 0.48537\n",
      "dfl: 1.69666\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/20 with hyperparameters: {'lr0': 0.00861, 'lrf': 0.01007, 'momentum': 0.90942, 'weight_decay': 0.00049, 'warmup_epochs': 3.27814, 'warmup_momentum': 0.95, 'box': 7.87962, 'cls': 0.47459, 'dfl': 1.42403, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/20 iterations complete  (4568.19s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55626 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.85738, 'metrics/recall(B)': 0.58883, 'metrics/mAP50(B)': 0.69097, 'metrics/mAP50-95(B)': 0.54129, 'val/box_loss': 0.9336, 'val/cls_loss': 0.78062, 'val/dfl_loss': 0.78887, 'fitness': 0.55626}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00861\n",
      "lrf: 0.01007\n",
      "momentum: 0.90942\n",
      "weight_decay: 0.00049\n",
      "warmup_epochs: 3.27814\n",
      "warmup_momentum: 0.95\n",
      "box: 7.87962\n",
      "cls: 0.47459\n",
      "dfl: 1.42403\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/20 with hyperparameters: {'lr0': 0.00861, 'lrf': 0.01007, 'momentum': 0.90992, 'weight_decay': 0.00049, 'warmup_epochs': 3.27976, 'warmup_momentum': 0.95, 'box': 7.87901, 'cls': 0.47434, 'dfl': 1.42209, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/20 iterations complete  (5702.90s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55626 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.85738, 'metrics/recall(B)': 0.58883, 'metrics/mAP50(B)': 0.69097, 'metrics/mAP50-95(B)': 0.54129, 'val/box_loss': 0.9336, 'val/cls_loss': 0.78062, 'val/dfl_loss': 0.78887, 'fitness': 0.55626}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00861\n",
      "lrf: 0.01007\n",
      "momentum: 0.90942\n",
      "weight_decay: 0.00049\n",
      "warmup_epochs: 3.27814\n",
      "warmup_momentum: 0.95\n",
      "box: 7.87962\n",
      "cls: 0.47459\n",
      "dfl: 1.42403\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/20 with hyperparameters: {'lr0': 0.00935, 'lrf': 0.01067, 'momentum': 0.93356, 'weight_decay': 0.00032, 'warmup_epochs': 2.98539, 'warmup_momentum': 0.80986, 'box': 8.16963, 'cls': 0.49208, 'dfl': 1.66009, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/20 iterations complete  (6863.50s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55626 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.85738, 'metrics/recall(B)': 0.58883, 'metrics/mAP50(B)': 0.69097, 'metrics/mAP50-95(B)': 0.54129, 'val/box_loss': 0.9336, 'val/cls_loss': 0.78062, 'val/dfl_loss': 0.78887, 'fitness': 0.55626}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00861\n",
      "lrf: 0.01007\n",
      "momentum: 0.90942\n",
      "weight_decay: 0.00049\n",
      "warmup_epochs: 3.27814\n",
      "warmup_momentum: 0.95\n",
      "box: 7.87962\n",
      "cls: 0.47459\n",
      "dfl: 1.42403\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/20 with hyperparameters: {'lr0': 0.00902, 'lrf': 0.00934, 'momentum': 0.89522, 'weight_decay': 0.00058, 'warmup_epochs': 3.10352, 'warmup_momentum': 0.95, 'box': 6.44454, 'cls': 0.56806, 'dfl': 1.17207, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/20 iterations complete  (7999.68s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/20 with hyperparameters: {'lr0': 0.00902, 'lrf': 0.00853, 'momentum': 0.89522, 'weight_decay': 0.00053, 'warmup_epochs': 3.02679, 'warmup_momentum': 0.95, 'box': 6.86155, 'cls': 0.56806, 'dfl': 1.12631, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/20 iterations complete  (9135.66s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/20 with hyperparameters: {'lr0': 0.00902, 'lrf': 0.00853, 'momentum': 0.89522, 'weight_decay': 0.00052, 'warmup_epochs': 3.02679, 'warmup_momentum': 0.82739, 'box': 6.28784, 'cls': 0.64079, 'dfl': 1.12631, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/20 iterations complete  (10273.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/20 with hyperparameters: {'lr0': 0.00895, 'lrf': 0.00968, 'momentum': 0.88746, 'weight_decay': 0.0006, 'warmup_epochs': 3.22245, 'warmup_momentum': 0.95, 'box': 6.69253, 'cls': 0.56806, 'dfl': 1.22203, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/20 iterations complete  (11411.03s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 11/20 with hyperparameters: {'lr0': 0.00907, 'lrf': 0.00934, 'momentum': 0.89522, 'weight_decay': 0.00058, 'warmup_epochs': 3.12904, 'warmup_momentum': 0.95, 'box': 6.44454, 'cls': 0.56806, 'dfl': 1.17207, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m11/20 iterations complete  (12546.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 12/20 with hyperparameters: {'lr0': 0.00902, 'lrf': 0.00839, 'momentum': 0.89873, 'weight_decay': 0.00053, 'warmup_epochs': 3.02679, 'warmup_momentum': 0.83105, 'box': 6.28784, 'cls': 0.64558, 'dfl': 1.11053, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m12/20 iterations complete  (13683.62s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 13/20 with hyperparameters: {'lr0': 0.00953, 'lrf': 0.00766, 'momentum': 0.87144, 'weight_decay': 0.00056, 'warmup_epochs': 2.98796, 'warmup_momentum': 0.95, 'box': 6.64639, 'cls': 0.45322, 'dfl': 1.3295, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m13/20 iterations complete  (14819.35s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56128 observed at iteration 7\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.81289, 'metrics/recall(B)': 0.65318, 'metrics/mAP50(B)': 0.70396, 'metrics/mAP50-95(B)': 0.54542, 'val/box_loss': 0.77437, 'val/cls_loss': 0.89672, 'val/dfl_loss': 0.64783, 'fitness': 0.56128}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train8\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.00934\n",
      "momentum: 0.89522\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 3.10352\n",
      "warmup_momentum: 0.95\n",
      "box: 6.44454\n",
      "cls: 0.56806\n",
      "dfl: 1.17207\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 14/20 with hyperparameters: {'lr0': 0.00902, 'lrf': 0.01037, 'momentum': 0.88183, 'weight_decay': 0.00057, 'warmup_epochs': 3.42364, 'warmup_momentum': 0.95, 'box': 6.3617, 'cls': 0.58825, 'dfl': 1.20702, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m14/20 iterations complete  (15953.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 15/20 with hyperparameters: {'lr0': 0.00913, 'lrf': 0.00838, 'momentum': 0.89981, 'weight_decay': 0.00054, 'warmup_epochs': 3.03696, 'warmup_momentum': 0.79441, 'box': 6.27524, 'cls': 0.64558, 'dfl': 1.12165, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m15/20 iterations complete  (17088.30s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 16/20 with hyperparameters: {'lr0': 0.00924, 'lrf': 0.01096, 'momentum': 0.87075, 'weight_decay': 0.0006, 'warmup_epochs': 3.94688, 'warmup_momentum': 0.80381, 'box': 6.77498, 'cls': 0.50831, 'dfl': 1.10251, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m16/20 iterations complete  (18223.27s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 17/20 with hyperparameters: {'lr0': 0.00923, 'lrf': 0.01096, 'momentum': 0.87021, 'weight_decay': 0.0006, 'warmup_epochs': 3.94688, 'warmup_momentum': 0.8097, 'box': 6.77498, 'cls': 0.50707, 'dfl': 1.10319, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m17/20 iterations complete  (19358.27s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 18/20 with hyperparameters: {'lr0': 0.00914, 'lrf': 0.01096, 'momentum': 0.8799, 'weight_decay': 0.0007, 'warmup_epochs': 4.05715, 'warmup_momentum': 0.74238, 'box': 6.77498, 'cls': 0.44057, 'dfl': 1.11318, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m18/20 iterations complete  (20496.97s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 19/20 with hyperparameters: {'lr0': 0.00981, 'lrf': 0.0094, 'momentum': 0.83845, 'weight_decay': 0.00044, 'warmup_epochs': 4.06471, 'warmup_momentum': 0.95, 'box': 4.81357, 'cls': 0.58356, 'dfl': 0.96621, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m19/20 iterations complete  (21634.61s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 20/20 with hyperparameters: {'lr0': 0.00873, 'lrf': 0.00791, 'momentum': 0.85501, 'weight_decay': 0.00054, 'warmup_epochs': 3.42094, 'warmup_momentum': 0.63089, 'box': 6.24469, 'cls': 0.60294, 'dfl': 1.14467, 'hsv_h': 0.0, 'hsv_s': 0.0, 'hsv_v': 0.0, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.0, 'mosaic': 0.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune2\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune2\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m20/20 iterations complete  (22774.71s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune2\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56883 observed at iteration 14\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.86456, 'metrics/recall(B)': 0.59408, 'metrics/mAP50(B)': 0.71226, 'metrics/mAP50-95(B)': 0.55289, 'val/box_loss': 0.76431, 'val/cls_loss': 0.94039, 'val/dfl_loss': 0.67194, 'fitness': 0.56883}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train15\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune2\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00902\n",
      "lrf: 0.01037\n",
      "momentum: 0.88183\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.42364\n",
      "warmup_momentum: 0.95\n",
      "box: 6.3617\n",
      "cls: 0.58825\n",
      "dfl: 1.20702\n",
      "hsv_h: 0.0\n",
      "hsv_s: 0.0\n",
      "hsv_v: 0.0\n",
      "degrees: 0.0\n",
      "translate: 0.0\n",
      "scale: 0.0\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.0\n",
      "mosaic: 0.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters on dataset for 30 epochs\n",
    "model.tune(data=\"../YOLO_Datasets/ElementLevel_train/data.yaml\", workers=1, epochs=30, iterations=20, optimizer='AdamW', plots=False, save=True, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, translate=0.0, scale=0.0, fliplr=0.0, mosaic=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
